{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "from utils.model import rebuild_kneenet\n",
    "from utils.preprocess_image import preprocess\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.googledrive_requests import download_from_googledrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = os.getenv(\"mendeley_dataset_file_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_filepath = \"data/mendeley/KneeKL299.zip\"\n",
    "download_from_googledrive(file_id, target_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and verify output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kneenet = rebuild_kneenet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_folders = ['data/mendeley/kneeKL299/test/' + str(x) for x in range(5)]\n",
    "n_images_per_score = 1\n",
    "images = []\n",
    "for img_folder in img_folders:\n",
    "    first_n_files = os.listdir(img_folder)[:n_images_per_score]\n",
    "    for file in first_n_files:\n",
    "        img = cv2.imread(os.path.join(img_folder,file), 0).astype(\"float\")\n",
    "        processed_image = preprocess(img)\n",
    "        input_image = processed_image.reshape((1,) + processed_image.shape)\n",
    "        input_image = torch.from_numpy(input_image)\n",
    "        input_image = input_image.float()\n",
    "        \n",
    "        \n",
    "        images.append(input_image)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[0][0][0],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.cat(images,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = kneenet(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = softmax(logits).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Captum Integrated Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Causes kernel to die:\n",
    "from captum.attr import IntegratedGradients\n",
    "integrated_gradients = IntegratedGradients(kneenet,multiply_by_inputs=True)\n",
    "integrated_gradients.attribute(images)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Captum DeepLift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import DeepLift\n",
    "DeepLift = DeepLift(kneenet,multiply_by_inputs=True)\n",
    "attr = DeepLift.attribute(images, target=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = attr.detach().numpy()\n",
    "positive_attr = attr * (attr>0)\n",
    "negative_attr = -1*attr * (attr<0)\n",
    "positive_attr = np.rollaxis(positive_attr,1,4)\n",
    "negative_attr = np.rollaxis(negative_attr,1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(img):\n",
    "    img = img - img.min()\n",
    "    img = img / img.max()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for image_num in range(n_images_per_score*5):\n",
    "    image_n = normalize(np.rollaxis(images[image_num].detach().numpy(),0,3))\n",
    "    pos_attr_n = normalize(positive_attr[image_num,:,:,0])\n",
    "    neg_attr_n = normalize(negative_attr[image_num,:,:,0])\n",
    "    \n",
    "    \n",
    "    image_n[:,:,0] = image_n[:,:,0] + pos_attr_n # Put positive attribution in the red channel\n",
    "    image_n[:,:,1] = image_n[:,:,1] + neg_attr_n # Put negative attribution in the green channel\n",
    "    \n",
    "    # Normalize image for matplotlib\n",
    "    image_n = image_n - image_n.min()\n",
    "    image_n = image_n / image_n.max()\n",
    "    \n",
    "    # Visualize\n",
    "    prediction = np.argmax(proba,axis=1)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.title(\"DeepLift explanation for prediction KL = \" + str(prediction[image_num]))\n",
    "    plt.imshow(image_n)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Captum Guided GradCam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import GuidedGradCam\n",
    "ggc = GuidedGradCam(kneenet,kneenet.features.denseblock4.denselayer32.conv2)\n",
    "# get attributes for all KL-classes\n",
    "attr_4 = ggc.attribute(images, target=4)\n",
    "attr_3 = ggc.attribute(images, target=3)\n",
    "attr_2 = ggc.attribute(images, target=2)\n",
    "attr_1 = ggc.attribute(images, target=1)\n",
    "attr_0 = ggc.attribute(images, target=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for image_num in range(n_images_per_score*5):\n",
    "    # Get predictions for all images\n",
    "    predictions = np.argmax(proba, axis=1)\n",
    "    # Get the attributes for the predicted class of the current image\n",
    "    attr = eval(f'attr_{predictions[image_num]}')\n",
    "    \n",
    "    # Normalize the image and the attributes\n",
    "    image_n = normalize(images[image_num].detach().numpy()).transpose((1, 2, 0))\n",
    "    attr_class = normalize(attr[predictions[image_num]].detach().numpy()).transpose((1, 2, 0))\n",
    "    \n",
    "    # Combine the image and the attributes\n",
    "    combined_image = normalize(image_n + attr_class)\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.title(\"DeepLift explanation for prediction KL = \" + str(predictions[image_num]))\n",
    "    plt.imshow(combined_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kneenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airmex_venv",
   "language": "python",
   "name": "airmex_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
